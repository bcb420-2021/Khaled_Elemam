---
title: "Assignment 1 - Data set selection and initial processing"
output:
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.
##### Note: The code used in this assignment is adopted from BCB420 lectures 3 to 5.

#### Install and load required libraries for the workflow.
```{r echo=TRUE, message=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")
if (!requireNamespace("GEOmetadb", quietly = TRUE))  BiocManager::install("GEOmetadb")
if (!requireNamespace("edgeR", quietly = TRUE))     BiocManager::install("edgeR")
if (!requireNamespace("biomaRt", quietly = TRUE))  BiocManager::install("biomaRt")
if (!requireNamespace("tidyverse", quietly = TRUE)) install.packages("tidyverse")     
if (!requireNamespace("gdtools", quietly = TRUE))    install.packages("gdtools")   
if (!requireNamespace("kableExtra", quietly = TRUE))  install.packages("kableExtra")   
if (!requireNamespace("data.table", quietly = TRUE))  install.packages("data.table")   

library(knitr)
library(GEOmetadb)
library(edgeR)
library(biomaRt) 
library(dplyr)
library(kableExtra)
library(data.table)
```

## Data exploration


##### GEO description of the dataset:
```{r echo=TRUE, message=FALSE}
gse <- getGEO("GSE151879",GSEMatrix=FALSE)
```
```{r}
kable(data.frame(head(Meta(gse))), format = "html")   
```


##### Information about the platform:
```{r, message=FALSE}
current_gpl <- names(GPLList(gse))[1]
current_gpl_info <- Meta(getGEO(current_gpl))
```
**Platform title** : `r current_gpl_info$title `  
**GEO accession** : `r current_gpl_info$geo_accession `  
**Submission date** : `r current_gpl_info$submission_date `  
**Last update date** : `r current_gpl_info$last_update_date `  
**Organism** : `r current_gpl_info$organism `  
**Number of GEO datasets that use this techology** : `r length(current_gpl_info$series_id) `  
**Number of GEO samples that use this technology** : `r length(current_gpl_info$sample_id) `    


##### Get the expression data:
```{r}
sub_dir <- "GSE151879"   
p <-file.path(getwd(), sub_dir)

#if the data exists no need to download it again
if (dir.exists(p)){
  setwd(p)
  Adult_path <- "GSE151879_raw_counts_genes.Adult_human_cardiomyocytes.txt.gz"
  Macrophages_path <- "GSE151879_raw_counts_genes.Macrophages.txt.gz"
  hESC_path <- "GSE151879_raw_counts_genes.hESC-derived_cardiomyocytes.txt.gz"
  
  Adult_human_CM = read.delim(Adult_path,header=TRUE,check.names = FALSE)
  Macrophages = read.delim(Macrophages_path,header=TRUE,check.names = FALSE)
  hESC_CM = read.delim (hESC_path,header=TRUE,check.names = FALSE)
  
} else{
  
  sfiles = getGEOSuppFiles("GSE151879")
  fnames = rownames(sfiles)
  
  # there are three supplemental files
  Adult_human_CM = read.delim(fnames[1],header=TRUE,check.names = FALSE)
  Macrophages = read.delim(fnames[2],header=TRUE,check.names = FALSE)
  hESC_CM = read.delim(fnames[3],header=TRUE,check.names = FALSE)

}

kable(Adult_human_CM[1:10,], format = "html")
kable(Macrophages[1:10,], format = "html")
kable(hESC_CM[1:10,], format = "html")
```
# Adult_CM only

##### Overview statistics for dataset:
```{r}
summary(Adult_human_CM)
```

```{r include=FALSE}
dim(Adult_human_CM)
#dim(Macrophages)
#dim(hESC_CM)


colnames(Adult_human_CM)
#colnames(Macrophages)
#colnames(hESC_CM)

summarized_gene_counts <- sort(table(Adult_human_CM$gene_id),decreasing = TRUE)
#summarized_gene_counts
kable(table(Adult_human_CM$gene_id)[1:3], format="html")
kable(summarized_gene_counts[which(Adult_human_CM$gene_id>1)[1:10]],)
## ask about no duplicates
##HEREEEe
```
### Filter weakly expresed features
```{r}
#translate out counts into counts per million using the edgeR package
cpms = cpm(Adult_human_CM[,2:7])
rownames(cpms) <- Adult_human_CM[,1]
# get rid of low counts
keep = rowSums(cpms >1) >=3
Adult_human_CM_filtered = Adult_human_CM[keep,]
dim(Adult_human_CM_filtered)
```


### Define the groups 
```{r}
samples <- data.frame(lapply(colnames(Adult_human_CM_filtered)[2:7],      
                             FUN=function(x){unlist(strsplit(x, split = "\\_"))[c(4,5)]})) 
colnames(samples) <- colnames(Adult_human_CM_filtered)[2:7] 
rownames(samples) <- c("condition","number")
samples <- data.frame(t(samples))
samples

```

# MAP IDs to gene names then check duplicates then look at HERE

### Connect to ensemble mart and limit to humans dataset

```{r}

ensembl <- useMart("ensembl")
ensembl = useDataset("hsapiens_gene_ensembl",mart=ensembl)

```

```{r include=FALSE}

#dim(listFilters(ensembl))
#kable(listFilters(ensembl)[1:10,1:2], type="html")


#listMarts()
datasets <- listDatasets(ensembl) 
kable(head(datasets),format = "html")
kable(head(datasets[grep(datasets$dataset,               
                         pattern = "sapiens"),]),format = "html")


biomart_human_filters <- listFilters(ensembl) 
kable(biomart_human_filters[ grep(biomart_human_filters$name,pattern="ensembl"),],    
      format="html") %>%   
  row_spec(3, background = "yellow")

kable(listAttributes(ensembl)[1:10,1:2], type="html")

kable(searchAttributes(mart = ensembl, 'hgnc') , format="html") %>% 
  row_spec(2, background = "yellow")

kable(searchAttributes(mart = ensembl, 'ensembl|hgnc')[1:12,] ,    
      format="html") %>%   row_spec(c(1,11), background = "yellow")



```

## Map human ensemble IDs to hgnc symbols
```{r}

conversion_stash <- "Adult_human_CM_id_conversion.rds"
if (file.exists(conversion_stash)) {  
  Adult_human_CM_id_conversion<- readRDS(conversion_stash) 
} else {   
    Adult_human_CM_id_conversion <- getBM(attributes = c("ensembl_gene_id","hgnc_symbol"),                
    filters = c("ensembl_gene_id"),                             
    values = Adult_human_CM_filtered$gene_id,                  
    mart = ensembl)   
    
    saveRDS(Adult_human_CM_id_conversion, conversion_stash)
}




## ask about no duplicates

```

### Check for duplicates
```{r}
#check duplicates
summarized_gene_counts <- sort(table(Adult_human_CM_id_conversion$hgnc_symbol),decreasing = TRUE)
kable(table(Adult_human_CM_id_conversion$hgnc_symbol)[1:3], format="html")
kable(summarized_gene_counts[which(Adult_human_CM_id_conversion$hgnc_symbol>1)[1:10]],)

```
### Merge mapped data frame with original filtered data frame
```{r}
# use data.table because it is much faster
colnames(Adult_human_CM_id_conversion) <- c("gene_id", "hgnc_symbol")
data_table_1 = data.table(Adult_human_CM_filtered, key="gene_id")
data_table_2 = data.table(Adult_human_CM_id_conversion, key="gene_id")

dt.merged <- merge(data_table_1, data_table_2, all = T)

```

```{r}
#reorder data frame
dt.merged <- dt.merged[, c(1,8,2,3,4,5,6,7)]
kable(dt.merged[1:5,],type = "html")
```

### Number of identifiers missing

#### I have 253 ids missing (NA) and 372 ids not mapped (empty string)
```{r}
ensembl_id_missing_gene <- dt.merged$gene_id[which(is.na(dt.merged$hgnc_symbol))]
ensembl_id_not_mapped <- dt.merged$gene_id[which(dt.merged$hgnc_symbol == "")]
length(ensembl_id_missing_gene)
length(ensembl_id_not_mapped)
```
```{r}
# View snippet of missing identifiers
kable(dt.merged[which(is.na(dt.merged$hgnc_symbol))][1:5])
kable(dt.merged[which(dt.merged$hgnc_symbol == "")][1:5])

```
#### I am unable because 



## Normalization


#### Check the total expression values in the two conditions.
```{r}
mean(sum(dt.merged$Adult_human_cardiomyocytes_Mock_1),
  sum(dt.merged$Adult_human_cardiomyocytes_Mock_2),
  sum(dt.merged$Adult_human_cardiomyocytes_Mock_3))

mean(sum(dt.merged$`Adult_human_cardiomyocytes_SARS-CoV2_1`),
  sum(dt.merged$`Adult_human_cardiomyocytes_SARS-CoV2_2`),
  sum(dt.merged$`Adult_human_cardiomyocytes_SARS-CoV2_3`))

```
#### Since the average total value between the two conditions is not equal we cannot normalize by library size because 
#### according to (Evans et. al Brief. Bioinform, 2018) normalization by library size assumes same total expression.


## Applying TMM to dataset 
##### I chose normalization by distribution using TMM because it adjusts for both library size and library composition.

```{r}

# Create our DGEList object to be used by edgeR
filtered_data_matrix <- as.matrix(dt.merged[,3:8]) 
rownames(filtered_data_matrix) <- dt.merged$gene_id
d = DGEList(counts=filtered_data_matrix, group =samples$condition )

# Calculate the normalization factors
d = calcNormFactors(d)
normalized_counts <- cpm(d)

```

### Box plots of the data before and after normalization
```{r}
data2plot <- log2(cpm(dt.merged[,3:8]))
boxplot(data2plot, xlab = "Samples", ylab = "log2 CPM",        
        las = 2, cex = 0.5, cex.lab = 0.5,     
        cex.axis = 0.5, main = "Adult CM RNASeq Samples Pre-Normalization")
#draw the median on each box plot
abline(h = median(apply(data2plot, 2, median)),        col = "green", lwd = 0.6, lty = "dashed")


data2plot <- log2(normalized_counts[,1:6])
boxplot(data2plot, xlab = "Samples", ylab = "log2 CPM",        
        las = 2, cex = 0.5, cex.lab = 0.5,     
        cex.axis = 0.5, main = "Adult CM RNASeq Samples Post-Normalization")
#draw the median on each box plot
abline(h = median(apply(data2plot, 2, median)),     
       col = "green", lwd = 0.6, lty = "dashed")
```
### Density plots before and after normalization.
```{r}
  counts_density <- apply(log2(cpm(dt.merged[,3:8])), 2, density)
  #calculate the limits across all the samples     
  xlim <- 0; ylim <- 0    
  for (i in 1:length(counts_density)) {     
    xlim <- range(c(xlim, counts_density[[i]]$x));    
    ylim <- range(c(ylim, counts_density[[i]]$y))    
    }
    cols <- rainbow(length(counts_density))     
    ltys <- rep(1, length(counts_density))
    #plot the first density plot to initialize the plot  
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n",  
         ylab="Smoothing density of log2-CPM", main="Denisty Plot Pre-Normalization", cex.lab = 0.8  )
    #plot each line   
    for (i in 1:length(counts_density)) lines(counts_density[[i]], col = cols[i])
    #create legend   
    legend("topright", colnames(data2plot),    
           col=cols, lty=ltys, cex=0.75,      
           border ="blue",  text.col = "green4",       
           merge = TRUE, bg = "gray90")
    
    
   counts_density <- apply(log2(normalized_counts[,1:6]), 2, density)
  #calculate the limits across all the samples     
  xlim <- 0; ylim <- 0    
  for (i in 1:length(counts_density)) {     
    xlim <- range(c(xlim, counts_density[[i]]$x));    
    ylim <- range(c(ylim, counts_density[[i]]$y))    
    }
    cols <- rainbow(length(counts_density))     
    ltys <- rep(1, length(counts_density))
    #plot the first density plot to initialize the plot  
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n",  
         ylab="Smoothing density of log2-CPM", main="Denisty Plot Post-Normalization", cex.lab = 0.8  )
    #plot each line   
    for (i in 1:length(counts_density)) lines(counts_density[[i]], col = cols[i])
    #create legend   
    legend("topright", colnames(data2plot),    
           col=cols, lty=ltys, cex=0.75,      
           border ="blue",  text.col = "green4",       
           merge = TRUE, bg = "gray90")
```


### MDS plot after normalization.

```{r}
hold <- vector()
for (i in 1:nrow(samples)) {
  lab <-c(samples$condition[i],samples$number[i])
  hold<- c(hold, paste(lab, collapse = "_") )
}
plotMDS(d, labels= hold, 
        col = c("darkgreen","blue")[factor(samples$condition)]) 
```

## Interpretation

-What are the control and test conditions of the dataset?
The controls are health hamster CM (Adult_CM_Mock) and the test conditions are patients infected by covid
Why is the dataset of interest to you?
Covid is very relavant right now and effects not fully understood
Were there expression values that were not unique for specific genes? How did you handle these?
I have 625 in total, I chose to keep them
Were there expression values that could not be mapped to current HUGO symbols?

How many outliers were removed?
from 57916 to 13200
How did you handle replicates?
I had no replicates/ duplicates other than the missing ids
What is the final coverage of your dataset?
13200 genes with 625 missing ids

